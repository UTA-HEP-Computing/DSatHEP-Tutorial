{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLKit Generators\n",
    "\n",
    "DLKit is a lightweight framework for managing a large number of Keras models. It provides a wrapper for models, tools to efficiently represent and read data, and analysis functions. This notebook overview how to use the DLKit generators to rapidly read and process data using a large number of processes/threads.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLGenerator\n",
    "\n",
    "For most HEP applications, the data is far too big to keep in memory. So during fitting, the data needs to be loaded on the fly. Keras uses python generators to read data as it trains. Since reading data can take some time, training in this way usually takes significantly longer than loading the data into memory first. To accelerate reading, Keras enables you to read the data using multiple parallel generators, but unfortunately their implementation has several issues that make it inefficient. So `DLKit` provides generators that not only run much faster, make it easy to read data.\n",
    "\n",
    "Let's try to read the LCD data using a `DLGenerator`. `DLKit` provides a generator which can read any files from various directories and correctly mix examples in the training data. But we can do the mixing before hand to save some time during training. A \"premixed\" file is available at `/data/LCD/LCD-Merged-All.h5`.\n",
    "\n",
    "First lets open the file up by hand to see what is inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECAL (3211264, 25, 25, 25)\n",
      "HCAL (3211264, 5, 5, 60)\n",
      "OneHot (3211264, 4)\n",
      "index (3211264,)\n",
      "target (3211264, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f=h5py.File('/data/LCD/LCD-Merged-All.h5')\n",
    "\n",
    "for k in f.keys():\n",
    "    try:\n",
    "        print k,f[k].shape\n",
    "    except:\n",
    "        print k,\"Not a tensor\"\n",
    "f.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see 3211264 events, which will require several hundred gigs of ram to load into memory. ECAL and HCAL are as described above. \"OneHot\" and \"index\" encode the true class of each example. \"target\" holds the energy of the particle. \n",
    "\n",
    "Now we can build a DLGenerator to read this file on the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "# A function to Normalize the data.\n",
    "\n",
    "from DLTools.ThreadedGenerator import DLh5FileGenerator\n",
    "\n",
    "def ConstantNormalization(Norms):\n",
    "    def NormalizationFunction(Ds):\n",
    "        out = []\n",
    "        for i,Norm in enumerate(Norms):\n",
    "            Ds[i]/=Norm\n",
    "            out.append(Ds[i])\n",
    "        return out\n",
    "    return NormalizationFunction\n",
    "\n",
    "def MergeInputs():\n",
    "    def f(X):\n",
    "        return [X[0],X[1]],X[2]\n",
    "    return f\n",
    "\n",
    "def MakePreMixGenerator(InputFile,BatchSize,Norms=[150.,1.],  Max=3e6,Skip=0, \n",
    "                        ECAL=True, HCAL=True, Energy=False, **kwargs):\n",
    "    datasets=[]\n",
    "\n",
    "    if ECAL:\n",
    "        datasets.append(\"ECAL\")\n",
    "    if HCAL:\n",
    "        datasets.append(\"HCAL\")\n",
    "\n",
    "    datasets.append(\"OneHot\")\n",
    "\n",
    "    if Energy:\n",
    "        datasets.append(\"target\")\n",
    "    \n",
    "    if ECAL and HCAL:\n",
    "        post_f=MergeInputs()\n",
    "    else:\n",
    "        post_f=False\n",
    "        \n",
    "    pre_f=ConstantNormalization(Norms)\n",
    "    \n",
    "    G=DLh5FileGenerator(files=[InputFile], datasets=datasets,\n",
    "                        batchsize=BatchSize,\n",
    "                        max=Max, skip=Skip, \n",
    "                        postprocessfunction=post_f,\n",
    "                        preprocessfunction=pre_f,\n",
    "                        **kwargs)\n",
    "    \n",
    "    return G\n",
    "\n",
    "MyGen=MakePreMixGenerator(\"/data/LCD/LCD-Merged-All.h5\",1024,[150.,150.,1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DLh5FileGenerator` takes a list of files and keys of objects to read, and delivers `BatchSize` number of examples as requested. Note that we not only read the data, but we use a `preprocessfunction` to normalize the data, and a `postprocessfunction` to format output as needed for Keras to train a ECAL and HCAL model simultaneously.\n",
    "\n",
    "Let's get some events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 25, 25, 25)\n",
      "(1024, 5, 5, 60)\n",
      "(1024, 4)\n"
     ]
    }
   ],
   "source": [
    "TheGen=MyGen.Generator()\n",
    "Data=TheGen.next()\n",
    "\n",
    "print Data[0][0].shape\n",
    "print Data[0][1].shape\n",
    "print Data[1].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Generator\n",
    "\n",
    "The DLKit's mixing generator take data separated into files and appropriately mix them and label them for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
