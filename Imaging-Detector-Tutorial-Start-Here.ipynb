{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging Detector Tutorial\n",
    "\n",
    "Particle detectors such as Calorimeters, Time Projection Chambers, and Cherenkov detectors produce 2D or 3D images of particle interactions that are typically 'reconsructed' by algorithms into features that enable identifying particle types and measuring particle energies. This tutorial presents simulated data from three different types of such detectors along with several challenging problems, solution to which will have significant impact to High Energy Physics. The goal is to establish working groups composed of physicists and machine learning researchers aimed at systematically searching for viable solutions to these problems, which in turn can be applied to running and future particle physics experiments. \n",
    "\n",
    "Along with these datasets, this tutorial provides software that facilitates rapidly reading these generally large datasets and collaboratively building and studying Deep Neural Networks. Most of the suggested problems are either completely setup or a small variation of an existing example, allowing participants to focus on the network architecture and training instead of worrying about data engineering issues. The tutorial will be run on the HEP Deep Learning cluster at University of Texas Arlington, which provides 80 CPU cores and 22 (mostly Pascal) NVidia GPUs. \n",
    "\n",
    "The plan for the tutorial is rather ambitious. The goal of the first session is to introduce the datasets, run a existing classification problem, and enable participants how to use their own models and perform hyperparameter scans. Participants are encouraged to use the two days between the tutorials to try ideas and perform scans. In the second session, participants will attempt to simulate data using Generative Adversorial Networks and to measure particle energy via regression. In the final day, participants will be presented the problem of inferring 3D spatial information from two 2D images. For the most part, participants will be lead through fully setup and running problems that use simple networks on down sampled data and not achieve desired performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Visualizing the Data\n",
    "\n",
    "[Note: this section is meant to serve as reference material. The information provided here will be presented in the introductory presentations. Participants are encourged to attempt any exercises presented in this section on their own time, and instead spend the time during the tutorial session to run Deep Neural Networks.]\n",
    "\n",
    "The [Particle Detector Introduction notebook](ParticleDetectorsIntro.ipynb) introduces the detectors and provides background information that non-physcists may find helpful to better understand the data and problems. Participants have a choice of dataset to use. This material is intended to facilitate making choosing the dataset.\n",
    "\n",
    "The [LCD Visualization notebook](LCD-Visualization.ipynb) notebook introduces the LCD dataset by  generating some simple visualizations. For comparison, the [LCD BDT notebook](LCD-BDT.ipynb) trains a Boosted Decision Tree (BDT) using features derived from the LCD images.\n",
    "\n",
    "The [LArIAT HandScan notebook](LArIAT-HandScan.ipynb) introduces the LArIAT dataset and leads participants to perform a handscan. This tutorial is aimed at participants with little experience in Machine Learning. It introduces basic python, numpy, and h5 file/data structure manipulation, ploting in matplotlib, and the concepts of problem formulation, training, and validation. \n",
    "\n",
    "The [LArIAT Visualization notebook](LArIAT-Visualization.ipynb) notebook introduces the LArIAT dataset by generating some 2D and 3D visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DLKit Framework\n",
    "\n",
    "[Note: this section is also meant to serve as reference material. A quick overview of the information provided here will be presented in the introductory presentations. Experienced participants may find this section useful to quickly use the datasets in their own codes. Others are encouraged to refer to this material as their needs become more sophisticated.]\n",
    "\n",
    "The DLKit is a lightweight Framework built on top of Keras and is intended to facilitate rapidly reading large datasets and easily studying a large number of models and collaborating with others. Experienced participants may choose to work on the datasets using their own tools, though they are encourged to use the data generators in DLKit for reading the data.\n",
    "\n",
    "The [DLKit Models Notebook](DLKit-Models.ipynb) introduces the data DLKit ModelWrapper. \n",
    "\n",
    "The [DLKit Generators Notebook](DLKit-Generators.ipynb) introduces the data generators in DLKit. \n",
    "\n",
    "The [LCD Data Generator notebook](LCD-Data-Generator.ipynb) demonstrates how to read, mix, and down sample the LArIAT data using the multi-threaded generators in DLKit. This notebook may be useful to experienced participants who wish to rapidly adapt their own code to run on this data sample.\n",
    "\n",
    "The [LArIAT Data Generator notebook](LArIAT-Data-Generator.ipynb) demonstrates how to read, mix, and down sample the LArIAT data using the multi-threaded generators in DLKit. This notebook may be useful to experienced participants who wish to rapidly adapt their own code to run on this data sample.\n",
    "\n",
    "The [NEXT Data Generator notebook](NEXT-Data-Generator.ipynb) demonstrates how to read, mix, and down sample the NEXT data using the multi-threaded generators in DLKit. This notebook may be useful to experienced participants who wish to rapidly adapt their own code to run on this data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an Experiment\n",
    "\n",
    "In this context, \"experiment\" refers to the process of developing a Deep Neural Network (DNN) to perform a specific task on specific data set. In DLKit, an experiment sets up a problem, reads the data, builds a DNN, trains it, and assess the performance.\n",
    "\n",
    "We will learn how to run an experiment by following the [CaloDNN Experiment Walkthrough notebook](CaloDNN-Experiment-Walkthrough.ipynb). Note that all of the other experiments work exactly the same way.\n",
    "\n",
    "The following three notebooks simply run each corresponding experiment within a notebook. Participants are encouraged to copy these notebooks and edit them as needed.\n",
    "\n",
    "   * [CaloDNN Experiment notebook](CaloDNN-Experiment.ipynb)\n",
    "   * [LArTPCDNN Experiment notebook](LArTPCDNN-Experiment.ipynb)\n",
    "   * [NEXTDNN Experiment notebook](NEXTDNN-Experiment.ipynb)\n",
    "   \n",
    "After training a single DNN model, you can closely examine its performance by loading the model, applying it to some test data, and making plots. The [CaloDNN Analyze Performance notebook](CaloDNN-AnalyzePerformance.ipynb) demonstrate how study a trained model in detail.\n",
    "\n",
    "After training a set of DNN models in a hyperparameter scan, you can compare performance of models using tools in DLKit. The [CaloDNN Analyze Scan notebook](CaloDNN-AnalyzeScan.ipynb) demonstrate how compare a large number of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1 Challenge\n",
    "\n",
    "All of the experiments presented above implement the simplest possible network, a fully connect DNN with width and depth specified or scanned. Since the dataset are composed of 2D and 3D images, Convolutional Neutral Networks (CNNs) are probably the best suited. \n",
    "\n",
    "We challenge participants to choose a dataset, implement a more sophisticated model than the fully connected DNN, perform a hyper-parameter scan in the batch queues, compare the performance of the trained models, and show the energy dependence of the performance for the best model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
