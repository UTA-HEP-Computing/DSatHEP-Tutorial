{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Boosted Decision Tree (BDT) using features from the LCD images\n",
    "\n",
    "First we import the classes that we need for opening and reading files. We use h5py to allow Python to read the h5 file format, and numpy for building arrays. We also have to import matplotlib for plotting on the first line, due to a strangeness in the matplotlib package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will open four different files, each containing 1000 events from a single-particle gun at different energies. There is one file for each of the following particles: charged pions, photons, neutron pions, and electrons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = \"/data/LCD/V1/HLF/\"\n",
    "dataFileNames = [\"EleEscan_HLF/EleEscan_1_10_HLF.h5\", \"GammaEscan_HLF/GammaEscan_1_10_HLF.h5\", \"ChPiEscan_HLF/ChPiEscan_1_10_HLF.h5\", \"Pi0Escan_HLF/Pi0Escan_1_10_HLF.h5\"]\n",
    "dataFiles = []\n",
    "for i in range(len(dataFileNames)):\n",
    "    dataFiles.append(h5py.File(dataDir + dataFileNames[i], \"r\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next command tells us all of the features stored in those files. We can make simple plots to look at these distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dataFiles[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the features is the pdgID (a unique integer number that represents the true identity of the incoming particle). You can plot the pdgID of the first data file by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataFiles[0]['pdgID']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first datafile was for incoming electrons (and positrons), and you can see in the distribution above the pdgIDs for every event are either equal to -11 or +11, which are the pdgID values for electrons and positrons (good!).\n",
    "\n",
    "Now let us plot the distribution of measured energy in the ECAL from the second input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataFiles[1]['ECALMeasuredEnergy']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will combine the samples, and explicitly label the electrons as class '0', photons as class '1', charged pions as class '2', and neutral pions as class '3'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "features = dataFiles[0].keys()\n",
    "# remove the \"Energy\" feature, which contains truth information about the particle gun\n",
    "features.remove('Energy')\n",
    "\n",
    "for count, feature in enumerate(features):\n",
    "    \n",
    "    newFeature = []\n",
    "    for fileN in range(len(dataFiles)):\n",
    "        newFeature += dataFiles[fileN][feature]\n",
    "\n",
    "    # use \"pdgID\" as the truth classifier y - all other features go into matrix X\n",
    "    if feature == 'pdgID':\n",
    "        y = 0 * np.array([int(abs(x) == 11) for x in newFeature]);\n",
    "        y = y + 1 * np.array([int(abs(x) == 22) for x in newFeature]);\n",
    "        y = y + 2 * np.array([int(abs(x) == 211) for x in newFeature]);\n",
    "        y = y + 3 * np.array([int(abs(x) == 111) for x in newFeature]);\n",
    "    else:\n",
    "        data.append(newFeature);\n",
    "\n",
    "X = np.column_stack(data)\n",
    "\n",
    "# remove all rows containing NaN and inf (from zero energy deposition, e.g.)\n",
    "y = y[np.isfinite(X).all(axis=1)]\n",
    "X = X[np.isfinite(X).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the sklearn package to perform the BDT training. First, we split the data into 2/3 training data and 1/3 test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=492)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a BDT with a maximum depth of 5 and the [AdaBoost-SAMME](http://algorithm-interest-group.me/assets/slides/AdaBoost.pdf) algorithm. We set 800 estimators and a learning rate of 0.5. If we wanted to, we could further split the training data into training and validation data. This would allow us to compare results from using different training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "bdt = AdaBoostClassifier(dt,\n",
    "                         algorithm='SAMME',\n",
    "                         n_estimators=800,\n",
    "                         learning_rate=0.5)\n",
    "\n",
    "bdt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the training is shown below.\n",
    "\n",
    "Precision (P) is defined as the number of true positives (T_p) over the number of true positives plus the number of false positives (F_p). E.g. the number of correctly identified electrons over all particles identified as electrons:\n",
    "\n",
    "    P = T_p / (T_p+F_p)  \n",
    "\n",
    "Recall (R) is defined as the number of true positives (T_p) over the number of true positives plus the number of false negatives (F_n). E.g. the number of correctly identified electrons over all truth electrons:\n",
    "\n",
    "    R = T_p / (T_p + F_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = bdt.predict(X_test)\n",
    "target_names = ['electron', 'photon', 'charged pion', 'neutral pion']\n",
    "print (classification_report(y_test, y_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that charged pions are identified very well, followed by electrons, but that the BDT has a bit of trouble distinguishing photons and neutronal pions. We can look at a ROC curve for identifying just these two classes - photons vs. neutral pions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_photon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores[indicesOfInterest][:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "scores = bdt.decision_function(X_test)\n",
    "\n",
    "# photons\n",
    "indicesOfInterest = np.array([(y == 1 or y == 3) for y in y_test])\n",
    "y_photon = np.array([int(y == 1) for y in y_test[indicesOfInterest]])\n",
    "print (\"Area under ROC curve: %.4f\"%(roc_auc_score(y_photon, scores[indicesOfInterest][:,1])))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_photon, scores[indicesOfInterest][:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)'%(roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can look at signal performance over background for a single class (let's say signal = photons, background = neutral pions) to test for overtraining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_train_test(clf, X_train, y_train, X_test, y_test, bins=30):\n",
    "    decisions = []\n",
    "    for X,y in ((X_train[indicesOfInterest], y_train[indicesOfInterest]), (X_test[indicesOfInterest], y_test[indicesOfInterest])):\n",
    "        d1 = clf.decision_function(X[y==1]).ravel()\n",
    "        d2 = clf.decision_function(X[y==3]).ravel()\n",
    "        decisions += [d1, d2]\n",
    "        \n",
    "    low = min(np.min(d) for d in decisions)\n",
    "    high = max(np.max(d) for d in decisions)\n",
    "    low_high = (low,high)\n",
    "    \n",
    "    plt.hist(decisions[0], color='r', alpha=0.5, range=low_high, bins=bins, histtype='stepfilled', normed=True, label='S (train)')\n",
    "    plt.hist(decisions[1], color='b', alpha=0.5, range=low_high, bins=bins, histtype='stepfilled', normed=True, label='B (train)')\n",
    "\n",
    "    hist, bins = np.histogram(decisions[2], bins=bins, range=low_high, normed=True)\n",
    "    scale = len(decisions[2]) / sum(hist)\n",
    "    err = np.sqrt(hist * scale) / scale\n",
    "    \n",
    "    width = (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.errorbar(center, hist, yerr=err, fmt='o', c='r', label='S (test)')\n",
    "    \n",
    "    hist, bins = np.histogram(decisions[3], bins=bins, range=low_high, normed=True)\n",
    "    scale = len(decisions[2]) / sum(hist)\n",
    "    err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "    plt.errorbar(center, hist, yerr=err, fmt='o', c='b', label='B (test)')\n",
    "\n",
    "    plt.xlabel(\"BDT output\")\n",
    "    plt.ylabel(\"Arbitrary units\")\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "compare_train_test(bdt, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
