{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LArIAT - 2D Data Examples / Hand Scan Tutorial\n",
    "## Training the Deep Neural Network in your head\n",
    "\n",
    "This notebook introduces the 2D LArIAT data set and leads you through setting up a handscan. The included exercises are meant to introduce basic python, numpy, and h5 file/data structure manipulation, ploting in matplotlib, and the concepts of problem formulation, training, and validation.\n",
    "\n",
    "## Introduction\n",
    "Before High Energy Physicists used computers with automatic reconstruction to turn raw data into features, they relied on hand scans performed by people. In this notebook we will setup a hand scan using the Liquid Argon TPC (LArTPC) data we looked at last time. The task will be to identify the type of particle. You will be the handscanner. The steps are as follows:\n",
    "\n",
    "    * Data Engineering: Load data from various files\n",
    "    * Training: Train the handscanner by presenting images of the data with the labels.\n",
    "    * Validation: Ask the handscanner to classify some randomly selected images, and see how well they do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering\n",
    "\n",
    "Our data is stored in a bunch of files. You can see the files by listing the directory using the unix \"ls\" command. You can call shell commands, like \"ls\", from Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDir2D=\"/data/LArIAT/h5_files_2D_3D/2D_h5/*\"\n",
    "%ls $BaseDir2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of files. Lets count how many... in python. There are a variety of ways of getting back a directory listing in python. Here's one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "Files=glob.glob(BaseDir2D)\n",
    "print \"Number of Files:\", len(Files)\n",
    "print \"First Filename:\", Files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the file names, you notice that they start with the type of particle. Each file contains a samples of \"events\". In each event, we simulated shooting a particle into the detector and stored the response. The name of the file specifies what type of particle was simulated in that file.\n",
    "\n",
    "Let's try to figure out what types. We'll loop over the file names, strip out the first part of the file name, and store it in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FileCount= {}  # Store the count here\n",
    "FileLists= {}  # Organize the files by particle type here.\n",
    "\n",
    "for aFile in Files:\n",
    "    # Lets strip the path (everything before the \"/\"s) and get the filename:\n",
    "    FileName=os.path.basename(aFile)\n",
    "    \n",
    "    # Now use everything before the first \"_\" as the particle name\n",
    "    ParticleName=FileName.split('_')[0]\n",
    "    \n",
    "    if ParticleName in FileCount.keys():\n",
    "        FileCount[ParticleName]+=1\n",
    "        FileLists[ParticleName].append(aFile)\n",
    "    else:\n",
    "        FileCount[ParticleName]=1\n",
    "        FileLists[ParticleName]= [aFile]\n",
    "    \n",
    "print \"Number of types of particles:\", len(FileCount.keys())\n",
    "print \"----------------------------------------------------------\"\n",
    "print \"Number of files for each particle type:\", FileCount\n",
    "print \"----------------------------------------------------------\"\n",
    "print \"First file of each type:\"\n",
    "for aFile in FileLists:\n",
    "    print aFile,\":\",FileLists[aFile][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count how many examples are in each file by open them up in h5py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f=h5py.File(FileLists[\"electron\"][0],\"r\")\n",
    "\n",
    "# Read the First N_Events. Data is stored as float16, lets store it as float32 to avoid overflows later when we sum.\n",
    "print \"Shape of the data:\", f[\"images\"].shape\n",
    "print \"Number of events in file:\", f[\"images\"].shape[0]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We will use matplotlib for most of our plotting. There are lots of tutorials and primers out there that you can find searching the web. A good tutorial can be found in the [Scipy Lectures](http://www.scipy-lectures.org/intro/matplotlib/matplotlib.html). Look through these on your own time, it is not necessary for doing these exercise.\n",
    "\n",
    "The raw data from a LArTPC detector looks like an image. The LArIAT detector, which we have simulated, has 2 readout views. The following code gives you an example how to plot these images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# Load the first electron file\n",
    "f=h5py.File(FileLists[\"electron\"][0],\"r\")\n",
    "\n",
    "# Get the images\n",
    "images=f[\"images\"]\n",
    "\n",
    "print \"Data shape:\", images.shape\n",
    "\n",
    "def PlotEvent(image):\n",
    "    # Make two plots. Create a 1 by 2 grid the plots.\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    ax2 = plt.subplot(1,2,2)\n",
    "\n",
    "    # Plot the first view. Note: [EventNumber, View] = [0,0]\n",
    "    ax1.imshow(image[0])\n",
    "\n",
    "    # Plot the second view \n",
    "    ax2.imshow(image[1])\n",
    "\n",
    "    # The data is 240 by 4096. Change the aspect ratio so the plot is not squished. \n",
    "    ax1.set_aspect(16)  \n",
    "    ax2.set_aspect(16) \n",
    "\n",
    "# Plot the 5th Event\n",
    "PlotEvent(np.array(images[4],dtype=\"float32\"))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2.1- Setup Training\n",
    "\n",
    "Write a function that takes a file, and creates a grid of plots showing the first N events. Use this function to plot the first 9 events in the first file of each particle type in a 3 by 3 grid. You only need to show one view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotEvents(FileName, N_Events):\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    # Fill in your solution here        \n",
    "    \n",
    "    ### END SOLUTION\n",
    "    pass\n",
    "\n",
    "N_Events=9\n",
    "\n",
    "for aFile in FileLists:\n",
    "    FileName=FileLists[aFile][0]\n",
    "    ParticleName=os.path.basename(FileName).split('_')[0]\n",
    "    \n",
    "    print ParticleName,\":\"\n",
    "    PlotEvents(FileName,N_Events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2.2- Train Yourself\n",
    "\n",
    "By looking closely at each particle type, identify at least one \"feature\" that would allow you to by eye uniquely identify that particle type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type you answer in this box.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "- muon/antimuon: your description here\n",
    "- electron/antielectron: your description here\n",
    "- pion: your description here\n",
    "- pionPlus/pionMinus: your description here\n",
    "- kaonPlus/kaonMinus: your description here\n",
    "- photon: your description here\n",
    "- nue/nuebar: your description here\n",
    "- numu/numubar: your description here\n",
    "- proton/antiproton: your description here\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Now we have to setup a validation process. We will first assign each particle type a unique index. Then we will load some events of each particle type, mix them while keeping track of the indecies. Finally we will present the images to the handscanner, ask them to classify, and keep track of how well they do.\n",
    "\n",
    "Read through and try to understand the following code which setups up 2 dictionaries we will use to uniquely identify particle types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assign index to particle type\n",
    "ParticleTypesIndexMap = {}\n",
    "\n",
    "for i,ParticleType in enumerate(FileLists.keys()):    \n",
    "    ParticleTypesIndexMap[ParticleType]=i\n",
    "    \n",
    "# Merge particle/anti-particle\n",
    "for ParticleName in ParticleTypesIndexMap:\n",
    "    if 'bar' in ParticleName:\n",
    "        try:\n",
    "            ParticleicleTypesIndexMap[ParticleName]=ParticleTypesIndexMap[ParticleName.split('bar')[0]]\n",
    "        except:\n",
    "           pass\n",
    "    \n",
    "    if 'anti' in ParticleName:\n",
    "        try:\n",
    "            ParticleTypesIndexMap[ParticleName]=ParticleTypesIndexMap[ParticleName.split('anti')[1]]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    if 'Minus' in ParticleName:\n",
    "        try:\n",
    "            ParticleTypesIndexMap[ParticleName]=ParticleTypesIndexMap[ParticleName.split('Minus')[0]+\"Plus\"]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "print \"Index map:\"\n",
    "print ParticleTypesIndexMap\n",
    "\n",
    "# Reverse Map\n",
    "ParticleTypesIndexMapR={}\n",
    "\n",
    "for p in ParticleTypesIndexMap:\n",
    "    if ParticleTypesIndexMap[p] not in ParticleTypesIndexMapR:\n",
    "        ParticleTypesIndexMapR[ParticleTypesIndexMap[p]]=p\n",
    "\n",
    "print \"Reverse Index map:\"\n",
    "print ParticleTypesIndexMapR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the data and mix them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_X = None\n",
    "Data_Y = None\n",
    "N_Events_perType=10\n",
    "\n",
    "for ParticleType in FileLists:\n",
    "    # Open the first file\n",
    "    FileName=FileLists[ParticleType][1] # we will take the 2nd file so we don't use the training sample for validation\n",
    "    print \"Opening:\",FileName\n",
    "    f=h5py.File(FileName,\"r\")\n",
    "    \n",
    "    # Get the images/features\n",
    "    images=np.array(f[\"images\"][:N_Events_perType])\n",
    "    \n",
    "    # Warn if not enough events\n",
    "    N_Events_read=images.shape[0]\n",
    "    if not N_Events_read==N_Events_perType:\n",
    "        print \"Warning: Sample\", FileName, \"had only\",N_Events_read,\"events.\"\n",
    "    \n",
    "    # Assign labels\n",
    "    labels=np.empty(N_Events_read)\n",
    "    labels.fill(ParticleTypesIndexMap[ParticleType])\n",
    "\n",
    "    # Store some of them\n",
    "    try:\n",
    "        # If we have already read some data, add to it\n",
    "        Data_X=np.concatenate((Data_X,np.array(images,dtype=\"float32\")))\n",
    "        Data_Y=np.concatenate((Data_Y,np.array(labels,dtype=\"float32\")))\n",
    "    except:\n",
    "        # If we haven't read any data yet\n",
    "        Data_X=images\n",
    "        Data_Y=labels\n",
    "    \n",
    "        \n",
    "    f.close()\n",
    "\n",
    "print Data_X.shape, Data_Y.shape\n",
    "\n",
    "def shuffle_in_unison_inplace(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "    \n",
    "Data_X,Data_Y=shuffle_in_unison_inplace(Data_X,Data_Y)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise 3.3.1\n",
    "\n",
    "The following code presents images and asks the handscanner for a type. Read through it carefully. Try it out. Then instrument this code so it keeps track of success and failures. The goal is to create a confusion matrix, a table that keeps track of how often each particle type is correctly identified and how often it is misidentified as any other type.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "View=0\n",
    "\n",
    "for image in Data_X:\n",
    "    PlotEvent(image)\n",
    "    plt.show()\n",
    "    \n",
    "    print \"Select Type from:\", ParticleTypesIndexMapR\n",
    "    try:\n",
    "        answer=int(raw_input('Input:'))\n",
    "    except ValueError:\n",
    "        print \"Not a number\"\n",
    "        \n",
    "    # Stop loop\n",
    "    if answer==-1:\n",
    "        break\n",
    "    \n",
    "    print \"You selected:\", ParticleTypesIndexMapR[answer]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise 3.3.2\n",
    "\n",
    "Make yourself the handscanner. Use above code to go through the full data sample and create a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4.1\n",
    "Write a function that downsamples all of images by summing samples to reduce the 4096 long dimension of the data.\n",
    "\n",
    "## Exercise 3.4.2\n",
    "Write a function that returns a sub-region in the 4096 long dimention where the total charge is max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
