{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2- Numpy\n",
    "\n",
    "Read through the following notebook to get an introduction to numpy: [Numpy Intro](jrjohansson-lectures/Lecture-2-Numpy.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1\n",
    "\n",
    "Let start with some basic reshape manipulations. Consider a classification task. We can imagine the training data X consisting of N examples each with M inputs, so the shape of X is (M,N). We usually express the output of the Neural Network, which for the training sample encodes the true class of each of the M examples in X, in a \"one-hot\" matrix of shape (N,C), where C is the number of classes and each row corresponds to the true class for the corresponding example in X. So for a given row Y[i], all elements are 0 except for the column corresponding to the true class.\n",
    "\n",
    "For example consider a classification task of separating between 4 classes. We'll call them A, B, C, and D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (4, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y=np.array( [ [0, 1, 0, 0], # Class B\n",
    "              [1, 0, 0, 0], # Class A\n",
    "              [0, 0, 1, 0], # Class C\n",
    "              [0, 0, 0, 1]  # Class D\n",
    "            ])\n",
    "\n",
    "print \"Shape of Y:\", Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets imagine that we want to change to a 2 classes instead by combining classes A with B and C with D. Use np.reshape and np.sum to create a new vector Y1. Hint: change the shape of Y into (8,2), sum along the correct axes, and change shape to (4,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose: [[0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n",
      "Reshape 8,2: [[0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]]\n",
      "Sum: [1 0 1 0 0 1 0 1]\n",
      "Answer:  [[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print \"Transpose:\", np.transpose(Y)\n",
    "print \"Reshape 8,2:\", np.transpose(Y).reshape((8,2))\n",
    "print \"Sum:\", np.sum(np.transpose(Y).reshape((8,2)),axis=1)\n",
    "\n",
    "Y1= np.sum(np.transpose(Y)\n",
    "           .reshape((8,2)),axis=1).reshape(4,2)\n",
    "print \"Answer: \",Y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2\n",
    "\n",
    "Oftentimes we find that neutral networks work best when their input is mostly between 0,1. Below, we create a random dataset that is normal distributed (mean of 4, sigma of 10). Shift the data so that the mean is 0.5 and 68% of the data lies between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11569850119\n",
      "-24.1491794142\n",
      "35.271067793\n",
      "93.0022630572\n"
     ]
    }
   ],
   "source": [
    "X=np.random.normal(4,10,1000)\n",
    "print np.mean(X)\n",
    "print np.min(X)\n",
    "print np.max(X)\n",
    "print np.var(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.84217094304e-17\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "X1=(X-np.mean(X))/math.sqrt(np.var(X)) # Replace X with your answer\n",
    "\n",
    "print np.mean(X1)\n",
    "print np.var(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3\n",
    "\n",
    "Using np.random.random and np.random.normal to generate two datasets. Then use np.where to repeat exercise 1.4 showing that one creates a flat distribution and the other does not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00069178490139 0.100583384413 : (1, 91)\n",
      "0.100583384413 0.200474983924 : (1, 111)\n",
      "0.200474983924 0.300366583435 : (1, 93)\n",
      "0.300366583435 0.400258182946 : (1, 102)\n",
      "0.400258182946 0.500149782457 : (1, 112)\n",
      "0.500149782457 0.600041381968 : (1, 78)\n",
      "0.600041381968 0.699932981479 : (1, 97)\n",
      "0.699932981479 0.799824580991 : (1, 92)\n",
      "0.799824580991 0.899716180502 : (1, 117)\n",
      "0.899716180502 0.999607780013 : (1, 105)\n",
      "0.999607780013 1.09949937952 : (1, 1)\n",
      "-24.1491794142 -18.2071546935 : (1, 3)\n",
      "-18.2071546935 -12.2651299727 : (1, 43)\n",
      "-12.2651299727 -6.32310525202 : (1, 102)\n",
      "-6.32310525202 -0.381080531301 : (1, 163)\n",
      "-0.381080531301 5.56094418942 : (1, 251)\n",
      "5.56094418942 11.5029689101 : (1, 218)\n",
      "11.5029689101 17.4449936309 : (1, 134)\n",
      "17.4449936309 23.3870183516 : (1, 64)\n",
      "23.3870183516 29.3290430723 : (1, 16)\n",
      "29.3290430723 35.271067793 : (1, 5)\n"
     ]
    }
   ],
   "source": [
    "X0=np.random.random(1000)\n",
    "\n",
    "def CheckFlatness(D,steps=10):\n",
    "    maxD=np.max(D)\n",
    "    minD=np.min(D)\n",
    "    i=minD\n",
    "    stepsize=(maxD-minD)/steps\n",
    "    while i<maxD:\n",
    "        print i,i+stepsize,\":\",np.shape(np.where((D<=(i+stepsize)) & (D>i) ))\n",
    "        i+=stepsize\n",
    "        \n",
    "CheckFlatness(X0)\n",
    "CheckFlatness(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.4\n",
    "\n",
    "Now lets play with some real data. We will load a file of example Neutrino interactions in LArTPC detector. There are 2 read out planes in the detector with 240 wires each, sampled 4096 times. Shift the images in the same way as exercise 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Eng', u'Track_length', u'enu_truth', u'features', u'lep_mom_truth', u'mode_truth', u'pdg']\n",
      "(10, 2, 240, 4096)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f=h5py.File(\"/data/LArIAT/h5_files/nue_CC_3-1469384613.h5\",\"r\")\n",
    "print f.keys()\n",
    "images=np.array(f[\"features\"][0:10],dtype=\"float32\")\n",
    "print images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0. -1. -1. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  1.  1. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [-1. -1.  0. ..., -1. -1. -1.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [-1. -1. -1. ..., -1. -1. -1.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "print images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45026\n",
      "626.457\n"
     ]
    }
   ],
   "source": [
    "print np.mean(images)\n",
    "print np.var(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 409)\n"
     ]
    }
   ],
   "source": [
    "def DownSample(Data,factor,Nx,Ny,sumabs=False):\n",
    "    if factor==0:\n",
    "        return np.reshape(Data,[Nx,Ny]),Ny\n",
    "\n",
    "    # Remove entries at the end so Down Sampling works\n",
    "    NyNew=Ny-Ny%factor\n",
    "    Data1=np.reshape(Data,[Nx,Ny])[:,0:NyNew]\n",
    "    \n",
    "    # DownSample \n",
    "    if sumabs:\n",
    "        a=abs(Data1.reshape([Nx*NyNew/factor,factor])).sum(axis=1).reshape([Nx,NyNew/factor])\n",
    "    else:\n",
    "        a=Data1.reshape([Nx*NyNew/factor,factor]).sum(axis=1).reshape([Nx,NyNew/factor])\n",
    "\n",
    "    return a,NyNew\n",
    "\n",
    "\n",
    "R,Ny=DownSample(images[0][1],10,240,4096)\n",
    "print R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
